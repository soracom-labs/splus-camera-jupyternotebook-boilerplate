{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run object detection on S+ Camera\n",
    "\n",
    "You can run your code cell by cell with Jupyter Notebook on S+ Camera here. To run a cell, click to focus and press Ctrl + Enter. Just try it with the cell below, then you will find output 'Welcom to S+ Jupyter Notebook Handson!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from pylab import *\n",
    "\n",
    "from surplus_camera_client import SurplusCameraClient\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "assert len(logger.handlers) == 1\n",
    "handler = logger.handlers[0]\n",
    "handler.setLevel(logging.WARNING)\n",
    "\n",
    "def download_and_save(url, path):\n",
    "    total_size = int(requests.head(url).headers.get('content-length'))\n",
    "    print(\"Starting download {}, {} bytes.\".format(url,total_size))\n",
    "    r = requests.get(url,stream=True)\n",
    "    downloaded = 0\n",
    "    checkpoints = [25,50,75,100]\n",
    "    checkpoint = checkpoints.pop(0)\n",
    "    with open(path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            downloaded += len(chunk)\n",
    "            progress = downloaded / total_size * 100\n",
    "            if checkpoint < progress:\n",
    "                print(\"{} bytes of {} bytes downloaded.\".format(downloaded,total_size))\n",
    "                checkpoint = checkpoints.pop(0)\n",
    "            f.write(chunk)\n",
    "    print(\"{} saved. File size: {} bytes.\\n\\n\".format(path, r.headers['content-length']))\n",
    "    \n",
    "def crop_and_resize(image):\n",
    "    image = deviceInterface.getCapture()\n",
    "    image = image[image_crop['y_from']:image_crop['y_to'],\n",
    "                  image_crop['x_from']:image_crop['x_to'],\n",
    "                  :]\n",
    "    image = cv2.resize(image, (int(image.shape[1] * 2), int(image.shape[0] * 2)))\n",
    "    return image\n",
    "\n",
    "print(\"Welcome to S+ Jupyter Notebook Handson!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try capture image from camera\n",
    "\n",
    "We have loaded and initialized reuiqred modules and so on. Now let's instantiate camera client and access an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_client = SurplusCameraClient.get_client()\n",
    "\n",
    "frame = camera_client.capture_image_as_nparray()\n",
    "\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did camera image show up? Now let's move on to preparation for object detection.\n",
    "\n",
    "## Download model and weights\n",
    "\n",
    "First, we download model(and weights) and labels. For this handson, we use [Caffe](https://caffe.berkeleyvision.org/) and MobileNet-SSD pre-trained model by [https://github.com/chuanqi305/MobileNet-SSD](https://github.com/chuanqi305/MobileNet-SSD). Please be noted that model(`MobileNetSSD_deploy.caffemodel`) is 20MB large, so it takes a while to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing model\n",
    "pbtext_path = './MobileNetSSD_deploy.prototxt'\n",
    "if not os.path.isfile(pbtext_path):\n",
    "    pbtext_url = 'https://raw.githubusercontent.com/djmv/MobilNet_SSD_opencv/master/MobileNetSSD_deploy.prototxt'\n",
    "    download_and_save(pbtext_url, pbtext_path)\n",
    "else:\n",
    "    print(\"Skipping download {} because it's already here.\".format(pbtext_path))\n",
    "\n",
    "weights_path = './MobileNetSSD_deploy.caffemodel'\n",
    "if not os.path.isfile(weights_path):\n",
    "    weights_url = 'https://raw.githubusercontent.com/djmv/MobilNet_SSD_opencv/master/MobileNetSSD_deploy.caffemodel'\n",
    "    download_and_save(weights_url, weights_path)\n",
    "else:\n",
    "    print(\"Skipping download {} because it's already here.\".format(weights_path))\n",
    "    \n",
    "#Labels of network.\n",
    "classNames = { 0: 'background',\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }\n",
    "\n",
    "#Load the Caffe model \n",
    "net = cv2.dnn.readNetFromCaffe(pbtext_path, weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup inference method\n",
    "\n",
    "Then, let's define functions for object detection. Surprisingly, object detection itself has been done by just 3 lines of code below.\n",
    "\n",
    "```\n",
    "blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5,127.5,127.5),False)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "```\n",
    "\n",
    "Following lines do post processing like adding text labels and bounding boxes on top of image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2\n",
    "\n",
    "def inference(frame):    \n",
    "    frame_resized = cv2.resize(frame,(300,300))\n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5,127.5,127.5),False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    #Size of frame resize (300x300)\n",
    "    cols = frame_resized.shape[1] \n",
    "    rows = frame_resized.shape[0]\n",
    "    \n",
    "    #Summary\n",
    "    detection_summary = {}\n",
    "\n",
    "    #For get the class and location of object detected, \n",
    "    # There is a fix index for class, location and confidence\n",
    "    # value in @detections array .\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] #Confidence of prediction \n",
    "        if confidence > threshold: # Filter prediction \n",
    "            class_id = int(detections[0, 0, i, 1]) # Class label\n",
    "\n",
    "            # Object location \n",
    "            xLeftBottom = int(detections[0, 0, i, 3] * cols) \n",
    "            yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "            xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "            yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "\n",
    "            # Factor for scale to original size of frame\n",
    "            heightFactor = frame.shape[0]/300.0  \n",
    "            widthFactor = frame.shape[1]/300.0 \n",
    "            # Scale object detection to frame\n",
    "            xLeftBottom = int(widthFactor * xLeftBottom) \n",
    "            yLeftBottom = int(heightFactor * yLeftBottom)\n",
    "            xRightTop   = int(widthFactor * xRightTop)\n",
    "            yRightTop   = int(heightFactor * yRightTop)\n",
    "            # Draw location of object  \n",
    "            cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),\n",
    "                          (0, 255, 0))\n",
    "\n",
    "            # Draw label and confidence of prediction in frame resized\n",
    "            if class_id in classNames:\n",
    "                label = classNames[class_id] + \": \" + str(confidence)\n",
    "                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "                yLeftBottom = max(yLeftBottom, labelSize[1])\n",
    "                cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]),\n",
    "                                     (xLeftBottom + labelSize[0], yLeftBottom + baseLine),\n",
    "                                     (255, 255, 255), cv2.FILLED)\n",
    "                cv2.putText(frame, label, (xLeftBottom, yLeftBottom),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "                #print(label) #print class and confidence\n",
    "                \n",
    "                if(classNames[class_id] in detection_summary ):\n",
    "                    detection_summary[classNames[class_id]]+=1\n",
    "                else:\n",
    "                    detection_summary[classNames[class_id]]=1\n",
    "    return frame, detection_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try inference!\n",
    "\n",
    "It's all set! Let's give a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = camera_client.capture_image_as_nparray()\n",
    "frame,detection_summary = inference(frame)\n",
    "print(detection_summary)\n",
    "\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "clear_output(wait=True)\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?\n",
    "\n",
    "Here is an exmaple for main logic loop which does followings.\n",
    "1. Capture image\n",
    "2. Object detection\n",
    "3. Show detection summary and send it to SORACOM Harvest\n",
    "4. If `person` is included in detection, it also sends image itself to SORACOM Harvest Files.\n",
    "\n",
    "You can stop anytime you would like to by pressing stop button above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    \n",
    "    frame = camera_client.capture_image_as_nparray()\n",
    "    frame,detection_summary = inference(frame)\n",
    "    print(\"Attempt #: {}\".format(str(i+1)))\n",
    "\n",
    "    if(len(detection_summary) > 0):\n",
    "    \n",
    "        print(\"\"\"Detection summary: {}\n",
    "Sent detection summary to SORACOM Harvest: {}\"\"\".format(\n",
    "                json.dumps(detection_summary),  \n",
    "                requests.post('http://harvest.soracom.io',json=detection_summary)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if 'person' in detection_summary:\n",
    "            result, jpeg = cv2.imencode('.jpg', frame)\n",
    "            upload_path = '/surplusdemo/detection.jpg'\n",
    "            sent_image = requests.post(\n",
    "                'http://harvest-files.soracom.io',\n",
    "                headers={'Content-Type':'image/jpeg'},\n",
    "                data=jpeg.tobytes()\n",
    "            )\n",
    "            print(\"Sent image with person detected to {}: {}\".format(\n",
    "                upload_path,\n",
    "                sent_image\n",
    "            ))\n",
    "    else:\n",
    "        print(\"Nothing detected.\")\n",
    "\n",
    "    plt.grid('off')\n",
    "    plt.axis('off')    \n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You walked through S+ Camera Basinc demo. You can start your own project with using this notebook as boilerplate :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}